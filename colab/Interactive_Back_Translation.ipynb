{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interactive Back Translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vietai/dab/blob/master/colab/Interactive_Back_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuzuxFlWeWh2",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation by Backtranslation\n",
        "\n",
        "Author:  [ Trieu H. Trinh](https://thtrieu.github.io/), Thang Le, Phat Hoang, [Thang Luong](http://thangluong.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlgMKwzE0wMu",
        "colab_type": "text"
      },
      "source": [
        "**MIT License**\n",
        "\n",
        "Copyright (c) [2019] [Trieu H. Trinh](https://thtrieu.github.io/)\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkgZPK_GpTF0",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Back translation is the process of translating a sentence in language A to language B and back to A. Due to randomess in the translation process, the output of this back-translation is a slight variation of the source sentence with the same semantic meaning. Back-translation is therefore a very useful technique for augmenting NLP datasets. To see such an example, checkout the [Colab here](https://colab.research.google.com/drive/1_I0KvFlHFyBcTRT3Bfx9BGLJcIHGJNrG) and also send love <3 and attention to our [Github repository](https://github.com/vietai/back_translate) for this project. \n",
        "\n",
        "In this Colab, we aim to minimally demonstrate examples of back-translation using our pretrained translation models. The process is simple: first we point to our pretrained models on Google Cloud Storage, then we use them to interactively back-translate. Although we provided only English-Vietnamese and English-French pairs, the code work with any other pairs as long as the checkpoints are obtained by training `transformer` on translation problems using `tensor2tensor`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Uar8Ae88MmM"
      },
      "source": [
        "## Step 1. Specify path to pretrained translation models\n",
        "\n",
        "You only need to run this step once.\n",
        "\n",
        "For English - French - English, please use the following settings:\n",
        "\n",
        "```\n",
        "model=transformer\n",
        "hparams_set=transformer_big\n",
        "from_problem=translate_enfr_wmt32k\n",
        "to_problem=translate_enfr_wmt32k_rev\n",
        "\n",
        "from_ckpt=checkpoints/translate_enfr_fren_uda/enfr/model.ckpt-500000\n",
        "to_ckpt=checkpoints/translate_enfr_fren_uda/fren/model.ckpt-500000\n",
        "\n",
        "from_data_dir=checkpoints/translate_enfr_fren_uda/\n",
        "to_data_dir=checkpoints/translate_enfr_fren_uda/\n",
        "```\n",
        "\n",
        "For English - Vietnamese - English, please use the following settings:\n",
        "\n",
        "\n",
        "```\n",
        "model=transformer\n",
        "hparams_set=transformer_tiny\n",
        "from_problem=translate_envi_iwslt32k\n",
        "to_problem=translate_vien_iwslt32k\n",
        "\n",
        "from_ckpt=checkpoints/translate_envi_iwslt32k_tiny/avg/\n",
        "to_ckpt=checkpoints/translate_vien_iwslt32k_tiny/avg/\n",
        "\n",
        "from_data_dir=data/translate_envi_iwslt32k/\n",
        "to_data_dir=data/translate_vien_iwslt32k/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRO6TXGLT4Qb",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "!pip install -q -U tensor2tensor\n",
        "\n",
        "import os\n",
        "from tensor2tensor.bin import t2t_decoder\n",
        "from tensor2tensor.models import transformer\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "%cd /content/\n",
        "src = '/content/dab'\n",
        "if not os.path.exists(src):\n",
        "    !git clone https://github.com/vietai/dab.git\n",
        "else:\n",
        "    %cd $src\n",
        "    !git pull\n",
        "\n",
        "%cd /\n",
        "!ls $src\n",
        "\n",
        "# Create hparams and the model\n",
        "model_name = \"transformer\"  # @param {type:\"string\"}\n",
        "hparams_set = \"transformer_tiny\"  # @param {type: \"string\"}\n",
        "from_problem = \"translate_envi_iwslt32k\"  # @param {type: \"string\"}\n",
        "to_problem = \"translate_vien_iwslt32k\"  # @param {type: \"string\"}\n",
        "google_cloud_bucket = 'vien-translation'  # @param {type: \"string\"}\n",
        "from_ckpt = 'checkpoints/translate_envi_iwslt32k_tiny/avg/'  # @param {type:\"string\"}\n",
        "to_ckpt = 'checkpoints/translate_vien_iwslt32k_tiny/avg/'  # @param {type:\"string\"}\n",
        "\n",
        "from_data_dir = 'data/translate_envi_iwslt32k/'  # @param {type:\"string\"}\n",
        "to_data_dir = 'data/translate_vien_iwslt32k/'  # @param {type:\"string\"}\n",
        "\n",
        "bucket_path = 'gs://' + google_cloud_bucket\n",
        "from_ckpt = os.path.join(bucket_path, from_ckpt)\n",
        "to_ckpt = os.path.join(bucket_path, to_ckpt)\n",
        "from_data_dir = os.path.join(bucket_path, from_data_dir)\n",
        "to_data_dir = os.path.join(bucket_path, to_data_dir)\n",
        "\n",
        "# Convert directory into checkpoints\n",
        "if tf.gfile.IsDirectory(from_ckpt):\n",
        "  from_ckpt = tf.train.latest_checkpoint(from_ckpt)\n",
        "if tf.gfile.IsDirectory(to_ckpt):\n",
        "  to_ckpt = tf.train.latest_checkpoint(to_ckpt)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwH1Iqau-udo",
        "colab_type": "text"
      },
      "source": [
        "## Step 2. Run back translation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ITqk72kujSK",
        "colab_type": "text"
      },
      "source": [
        "### a. Back-translating an English sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEoMmnXO2UaZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "beam_size = 2 #@param {type: \"integer\"}\n",
        "alpha = 0.6  #@param {type: \"number\"}\n",
        "\n",
        "decode_hparams = \"beam_size={},alpha={}\".format(beam_size, alpha)\n",
        "\n",
        "# >>> Hi there.\n",
        "# Paraphrased: Hello .\n",
        "# >>> How are you doing today?\n",
        "# Paraphrased: How do you do today ?\n",
        "# >>> Thank you so much.\n",
        "# Paraphrased: Thank you very much .\n",
        "# >>> I used to dream of becoming a soccer player\n",
        "# Paraphrased: I 've been dreaming to become a football player .\n",
        "# >>> It is definitely our duty to push the boundary of scientific research.\n",
        "# Paraphrased: It 's certainly our mission to push the boundaries of science .\n",
        "\n",
        "!python $src/back_translate.py \\\n",
        "--decode_hparams=$decode_hparams \\\n",
        "--model=$model_name \\\n",
        "--hparams_set=$hparams_set \\\n",
        "--from_problem=$from_problem \\\n",
        "--to_problem=$to_problem \\\n",
        "--from_ckpt=$from_ckpt \\\n",
        "--to_ckpt=$to_ckpt \\\n",
        "--from_data_dir=$from_data_dir \\\n",
        "--to_data_dir=$to_data_dir \\\n",
        "--backtranslate_interactively\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB8WUiyaul48",
        "colab_type": "text"
      },
      "source": [
        "### b. Back translating sentences in the intermediate language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ5IMgC1uJPe",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "beam_size = 2 #@param {type: \"integer\"}\n",
        "alpha = 0.6  #@param {type: \"number\"}\n",
        "\n",
        "decode_hparams = \"beam_size={},alpha={}\".format(beam_size, alpha)\n",
        "\n",
        "from_problem, to_problem = to_problem, from_problem\n",
        "from_ckpt, to_ckpt = to_ckpt, from_ckpt\n",
        "from_data_dir, to_data_dir = to_data_dir, from_data_dir\n",
        "\n",
        "# Tôi từng ước mơ trở thành cầu thủ bóng đá\n",
        "!python $src/back_translate.py \\\n",
        "--decode_hparams=$decode_hparams \\\n",
        "--model=$model_name \\\n",
        "--hparams_set=$hparams_set \\\n",
        "--from_problem=$from_problem \\\n",
        "--to_problem=$to_problem \\\n",
        "--from_ckpt=$from_ckpt \\\n",
        "--to_ckpt=$to_ckpt \\\n",
        "--from_data_dir=$from_data_dir \\\n",
        "--to_data_dir=$to_data_dir \\\n",
        "--backtranslate_interactively\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn5aGaGvADKL",
        "colab_type": "text"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "This work is made possible by [VietAI](http://vietai.org/).\n",
        "\n",
        "## References\n",
        "\n",
        "1. Improving Neural Machine Translation Models with Monolingual Data - Sennrich et al. , 2016a  ([arxiv](https://arxiv.org/abs/1511.06709))\n",
        "2. Understanding Back-Translation at Scale - Edunov, Sergey, et al., 2018 ([arxiv](https://arxiv.org/abs/1808.09381))\n",
        "3. T2T translate vi<->en tiny tpu - Trieu H. Trinh ([colab](https://colab.research.google.com/drive/1Bx5HfxbmXnMK7kBLHlmGyhVhQVVrDI0p))\n",
        "4. Sentiment Analysis + Back translation - Trieu H. Trinh ([colab](https://colab.research.google.com/drive/1_I0KvFlHFyBcTRT3Bfx9BGLJcIHGJNrG#scrollTo=7yvhttVKTkZu))\n",
        "5. Tensor2Tensor Intro - Tensor2Tensor Team([colab](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb))\n"
      ]
    }
  ]
}