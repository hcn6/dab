{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interactive Back Translation with Style.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntkchinh/dab/blob/master/Interactive_Back_Translation_with_Style.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuzuxFlWeWh2"
      },
      "source": [
        "# Data Augmentation by Backtranslation\n",
        "\n",
        "Author:  [ Trieu H. Trinh](https://thtrieu.github.io/), Thang Le, Phat Hoang, [Thang Luong](http://thangluong.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlgMKwzE0wMu"
      },
      "source": [
        "**MIT License**\n",
        "\n",
        "Copyright (c) [2019] [Trieu H. Trinh](https://thtrieu.github.io/)\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkgZPK_GpTF0"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Back translation is the process of translating a sentence in language A to language B and back to A. Due to randomess in the translation process, the output of this back-translation is a slight variation of the source sentence with the same semantic meaning. Back-translation is therefore a very useful technique for augmenting NLP datasets. To see such an example, checkout the [Colab here](https://colab.research.google.com/drive/1_I0KvFlHFyBcTRT3Bfx9BGLJcIHGJNrG) and also send love <3 and attention to our [Github repository](https://github.com/vietai/back_translate) for this project. \n",
        "\n",
        "In this Colab, we aim to minimally demonstrate examples of back-translation using our pretrained translation models. The process is simple: first we point to our pretrained models on Google Cloud Storage, then we use them to interactively back-translate. Although we provided only English-Vietnamese and English-French pairs, the code work with any other pairs as long as the checkpoints are obtained by training `transformer` on translation problems using `tensor2tensor`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uar8Ae88MmM"
      },
      "source": [
        "## Step 1. Specify path to pretrained translation models\n",
        "\n",
        "You only need to run this step once.\n",
        "\n",
        "For English - French - English, please use the following settings:\n",
        "\n",
        "```\n",
        "model=transformer\n",
        "hparams_set=transformer_big\n",
        "from_problem=translate_enfr_wmt32k\n",
        "to_problem=translate_enfr_wmt32k_rev\n",
        "\n",
        "from_ckpt=checkpoints/translate_enfr_fren_uda/enfr/model.ckpt-500000\n",
        "to_ckpt=checkpoints/translate_enfr_fren_uda/fren/model.ckpt-500000\n",
        "\n",
        "from_data_dir=checkpoints/translate_enfr_fren_uda/\n",
        "to_data_dir=checkpoints/translate_enfr_fren_uda/\n",
        "```\n",
        "\n",
        "For English - Vietnamese - English, please use the following settings:\n",
        "\n",
        "\n",
        "```\n",
        "model=transformer\n",
        "hparams_set=transformer_tiny\n",
        "from_problem=translate_envi_iwslt32k\n",
        "to_problem=translate_vien_iwslt32k\n",
        "\n",
        "from_ckpt=checkpoints/translate_envi_iwslt32k_tiny/avg/\n",
        "to_ckpt=checkpoints/translate_vien_iwslt32k_tiny/avg/\n",
        "\n",
        "from_data_dir=data/translate_envi_iwslt32k/\n",
        "to_data_dir=data/translate_vien_iwslt32k/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRO6TXGLT4Qb"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q -U tensor2tensor\n",
        "!pip install tensorflow-datasets==3.2.1\n",
        "\n",
        "import os\n",
        "from tensor2tensor.bin import t2t_decoder\n",
        "from tensor2tensor.models import transformer\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gadLO92L41lX",
        "outputId": "5896dac3-0935-4dd9-928e-b6bcff2da6f3"
      },
      "source": [
        "%cd /content/\n",
        "src = '/content/dab'\n",
        "if not os.path.exists(src):\n",
        "    !git clone https://github.com/ntkchinh/dab.git\n",
        "else:\n",
        "    %cd $src\n",
        "    !git pull\n",
        "\n",
        "%cd /\n",
        "!ls $src"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/dab\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/ntkchinh/dab\n",
            "   05063ab..df991bd  master     -> origin/master\n",
            "Updating 05063ab..df991bd\n",
            "Fast-forward\n",
            " decoding.py | 6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 3 insertions(+), 3 deletions(-)\n",
            "/\n",
            "back_translate.py  gif\t\t__pycache__\tt2t_decoder.py\n",
            "colab\t\t   LICENSE\tREADME.md\tt2t_trainer.py\n",
            "decoding.py\t   problems.py\tt2t_datagen.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PMp-v1wqsg_",
        "outputId": "05d700aa-624c-4ebc-f3df-00c079b26d81"
      },
      "source": [
        "# Create hparams and the model\n",
        "model_name = \"transformer\"  # @param {type:\"string\"}\n",
        "hparams_set = \"transformer_base\"  # @param {type: \"string\"}\n",
        "from_problem = \"translate_class11_appendtag_envi_iwslt32k\"  # @param {type: \"string\"}\n",
        "to_problem = \"translate_class11_appendtag_vien_iwslt32k\"  # @param {type: \"string\"}\n",
        "google_cloud_bucket = 'best_vi_translation'  # @param {type: \"string\"}\n",
        "from_ckpt = 'checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/'  # @param {type:\"string\"}\n",
        "to_ckpt = 'checkpoints/translate_class11_appendtag_vien_base_1000k/SAVE/'  # @param {type:\"string\"}\n",
        "\n",
        "from_data_dir = 'data/translate_class11_appendtag_envi_iwslt32k/'  # @param {type:\"string\"}\n",
        "to_data_dir = 'data/translate_class11_appendtag_vien_iwslt32k/'  # @param {type:\"string\"}\n",
        "\n",
        "bucket_path = 'gs://' + google_cloud_bucket\n",
        "from_ckpt_dir = os.path.join(bucket_path, from_ckpt)\n",
        "to_ckpt_dir = os.path.join(bucket_path, to_ckpt)\n",
        "from_data_dir = os.path.join(bucket_path, from_data_dir)\n",
        "to_data_dir = os.path.join(bucket_path, to_data_dir)\n",
        "\n",
        "# Convert directory into checkpoints\n",
        "if tf.gfile.IsDirectory(from_ckpt_dir):\n",
        "  print('yes')\n",
        "  # from_ckpt = tf.train.latest_checkpoint(from_ckpt_dir)\n",
        "  from_ckpt = os.path.join(from_ckpt_dir, 'model.ckpt-1000000')  # <- this is not a \"dir\"\n",
        "if tf.gfile.IsDirectory(to_ckpt_dir):\n",
        "  print('yes')\n",
        "  # to_ckpt = tf.train.latest_checkpoint(to_ckpt_dir)\n",
        "  to_ckpt = os.path.join(to_ckpt_dir, 'model.ckpt-1000000')\n",
        "print(from_ckpt_dir)\n",
        "print(to_ckpt_dir)\n",
        "\n",
        "print(from_ckpt)\n",
        "print(to_ckpt)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yes\n",
            "yes\n",
            "gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/\n",
            "gs://best_vi_translation/checkpoints/translate_class11_appendtag_vien_base_1000k/SAVE/\n",
            "gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/model.ckpt-1000000\n",
            "gs://best_vi_translation/checkpoints/translate_class11_appendtag_vien_base_1000k/SAVE/model.ckpt-1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVrW136Nm_Yx",
        "outputId": "42c0583f-59b8-4f7b-84a3-60f143ee9bcd"
      },
      "source": [
        "\n",
        "def setup_tpu():\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "  # Mount the bucket to colab, so that python package os can access to it.\n",
        "  # First we install gcsfuse to be able to mount Google Cloud Storage with Colab.\n",
        "  print('\\nInstalling gcsfuse')\n",
        "  !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "  !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "  !apt -qq update\n",
        "  !apt -qq install gcsfuse\n",
        "\n",
        "  bucket = google_cloud_bucket\n",
        "  print('Mounting bucket {} to local.'.format(bucket))\n",
        "  mount_point = '/content/{}'.format(bucket)\n",
        "  if not os.path.exists(mount_point):\n",
        "    tf.gfile.MakeDirs(mount_point)\n",
        "  \n",
        "  !fusermount -u $mount_point\n",
        "  !gcsfuse --implicit-dirs $bucket $mount_point\n",
        "  print('\\nMount point content:')\n",
        "  !ls $mount_point\n",
        "\n",
        "  # First we Connect to the TPU pod.\n",
        "  tpu_address = ''\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "    with tf.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "      # Upload credentials to TPU.\n",
        "      with open('/content/adc.json', 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "      tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)\n",
        "\n",
        "  return mount_point, tpu_address\n",
        "\n",
        "mount_point, tpu_address = setup_tpu()\n",
        "  \n",
        "print('\\nMount point: {}'.format(mount_point))\n",
        "print('TPU address: {}'.format(tpu_address))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Installing gcsfuse\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1974  100  1974    0     0  98700      0 --:--:-- --:--:-- --:--:-- 98700\n",
            "OK\n",
            "48 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.33.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "Mounting bucket best_vi_translation to local.\n",
            "Using mount point: /content/best_vi_translation\n",
            "2021/03/15 06:21:26.110260 Opening GCS connection...\n",
            "2021/03/15 06:21:26.604716 Mounting file system...\n",
            "2021/03/15 06:21:26.605058 File system has been successfully mounted.\n",
            "\n",
            "Mount point content:\n",
            "checkpoints  data  raw\n",
            "\n",
            "Mount point: /content/best_vi_translation\n",
            "TPU address: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwH1Iqau-udo"
      },
      "source": [
        "## Step 2. Run back translation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ITqk72kujSK"
      },
      "source": [
        "### a. Back-translating an English sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEoMmnXO2UaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fded1ed8-2881-40f1-a5c1-b8c5fdea8240"
      },
      "source": [
        "beam_size = 2 #@param {type: \"integer\"}\n",
        "alpha = 0.6  #@param {type: \"number\"}\n",
        "\n",
        "decode_hparams = \"beam_size={},alpha={}\".format(beam_size, alpha)\n",
        "\n",
        "# >>> Hi there., then quietly left as the members of the press swarmed around her .\n",
        "# Paraphrased: Hello .\n",
        "# >>> How are you doing today?\n",
        "# Paraphrased: How do you do today ?\n",
        "# >>> Thank you so much.\n",
        "# Paraphrased: Thank you very much .\n",
        "# >>> I used to dream of becoming a soccer player\n",
        "# Paraphrased: I 've been dreaming to become a football player .\n",
        "# >>> It is definitely our duty to push the boundary of scientific research.\n",
        "# Paraphrased: It 's certainly our mission to push the boundaries of science .\n",
        "\n",
        "!python $src/back_translate.py \\\n",
        "--decode_hparams=$decode_hparams \\\n",
        "--model=$model_name \\\n",
        "--hparams_set=$hparams_set \\\n",
        "--from_problem=$from_problem \\\n",
        "--to_problem=$to_problem \\\n",
        "--output_dir=$from_ckpt_dir \\\n",
        "--from_ckpt=$from_ckpt \\\n",
        "--to_ckpt=$to_ckpt \\\n",
        "--from_data_dir=$from_data_dir \\\n",
        "--to_data_dir=$to_data_dir \\\n",
        "--backtranslate_interactively\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/dab/back_translate.py:61: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/dab/back_translate.py:61: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/dab/back_translate.py:61: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/dab/back_translate.py:61: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/dab/back_translate.py:66: The name tf.gfile.IsDirectory is deprecated. Please use tf.io.gfile.isdir instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/dab/back_translate.py:66: The name tf.gfile.IsDirectory is deprecated. Please use tf.io.gfile.isdir instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/utils/trainer_lib.py:248: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/utils/trainer_lib.py:248: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "INFO:tensorflow:sync=False\n",
            "INFO:tensorflow:sync=False\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:caching_devices: None\n",
            "INFO:tensorflow:caching_devices: None\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff206ebf10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/', '_session_creation_timeout_secs': 7200, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7eff206ebf90>}\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff206ebf10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/', '_session_creation_timeout_secs': 7200, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7eff206ebf90>}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7eff21707d40>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7eff21707d40>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "INFO:tensorflow:sync=False\n",
            "INFO:tensorflow:sync=False\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:caching_devices: None\n",
            "INFO:tensorflow:caching_devices: None\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff20494890>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/', '_session_creation_timeout_secs': 7200, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7eff204948d0>}\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff20494890>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/', '_session_creation_timeout_secs': 7200, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7eff204948d0>}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7eff21707ef0>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7eff21707ef0>) includes params argument, but params are not passed to Estimator.\n",
            "Loading from gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/model.ckpt-1000000 ..\n",
            "Loading from gs://best_vi_translation/checkpoints/translate_class11_appendtag_vien_base_1000k/SAVE/model.ckpt-1000000 ..\n",
            "WARNING:tensorflow:From /content/dab/decoding.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/dab/decoding.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:decode_hp.batch_size not specified; default=1\n",
            "INFO:tensorflow:decode_hp.batch_size not specified; default=1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:Beam Decoding with beam size 2\n",
            "INFO:tensorflow:Beam Decoding with beam size 2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/layers/common_attention.py:931: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/layers/common_attention.py:931: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/utils/expert_utils.py:621: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/utils/expert_utils.py:621: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/utils/expert_utils.py:621: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensor2tensor/utils/expert_utils.py:621: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2021-03-15 06:38:45.002496: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-03-15 06:38:45.002694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611a2a92680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-15 06:38:45.002726: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-15 06:38:45.004466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-15 06:38:45.138349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:38:45.139046: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611a2a92f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-15 06:38:45.139078: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-03-15 06:38:45.139282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:38:45.139814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-15 06:38:45.140113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 06:38:45.141532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-15 06:38:45.142993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-15 06:38:45.143339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-15 06:38:45.144810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-15 06:38:45.145469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-15 06:38:45.148484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-15 06:38:45.148602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:38:45.149181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:38:45.149681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-15 06:38:45.149740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 06:38:45.150951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-15 06:38:45.150977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-15 06:38:45.150987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-15 06:38:45.151107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:38:45.151733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:38:45.152257: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-15 06:38:45.152298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14354 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from gs://best_vi_translation/checkpoints/translate_class11_appendtag_vien_base_1000k/SAVE/model.ckpt-1000000\n",
            "INFO:tensorflow:Restoring parameters from gs://best_vi_translation/checkpoints/translate_class11_appendtag_vien_base_1000k/SAVE/model.ckpt-1000000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "2021-03-15 06:38:57.389909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:decode_hp.batch_size not specified; default=1\n",
            "INFO:tensorflow:decode_hp.batch_size not specified; default=1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:Beam Decoding with beam size 2\n",
            "INFO:tensorflow:Beam Decoding with beam size 2\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2021-03-15 06:39:03.209287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:39:03.209846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-15 06:39:03.209939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 06:39:03.209975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-15 06:39:03.210002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-15 06:39:03.210025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-15 06:39:03.210046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-15 06:39:03.210068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-15 06:39:03.210089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-15 06:39:03.210201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:39:03.210765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:39:03.211269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-15 06:39:03.211311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-15 06:39:03.211326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-15 06:39:03.211339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-15 06:39:03.211441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:39:03.212001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 06:39:03.212527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14354 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/model.ckpt-1000000\n",
            "INFO:tensorflow:Restoring parameters from gs://best_vi_translation/checkpoints/translate_class11_appendtag_envi_base_1000k/SAVE/model.ckpt-1000000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            ">>> Hi\n",
            "Translated      : Xin chào \n",
            "Back-translated : Hello .\n",
            ">>> How are you today?\n",
            "Translated      : Hôm nay các anh có khỏe không ? \n",
            "Back-translated : How were you doing today ?\n",
            ">>> I love you, harry \\ TED talk\n",
            "Translated      : Tôi yêu bạn, harry\n",
            "Back-translated : I love you, harry .\n",
            ">>> I love you, harry \\ movie\n",
            "Translated      : Tôi yêu cô, harry\n",
            "Back-translated : I 'm in love with you, harry .\n",
            ">>> Hi\n",
            "Translated      : Xin chào \n",
            "Back-translated : Hello .\n",
            ">>> How are you today?\n",
            "Translated      : Hôm nay các anh có khỏe không ? \n",
            "Back-translated : How were you doing today ?\n",
            ">>> I love you, harry \\ TED talk\n",
            "Translated      : Tôi yêu bạn, harry\n",
            "Back-translated : I love you, harry .\n",
            ">>> I love you, harry \\ movie\n",
            "Translated      : Tôi yêu cô, harry\n",
            "Back-translated : I 'm in love with you, harry .\n",
            ">>> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB8WUiyaul48"
      },
      "source": [
        "### b. Back translating sentences in the intermediate language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ5IMgC1uJPe",
        "cellView": "form"
      },
      "source": [
        "beam_size = 2 #@param {type: \"integer\"}\n",
        "alpha = 0.6  #@param {type: \"number\"}\n",
        "\n",
        "decode_hparams = \"beam_size={},alpha={}\".format(beam_size, alpha)\n",
        "\n",
        "from_problem, to_problem = to_problem, from_problem\n",
        "from_ckpt, to_ckpt = to_ckpt, from_ckpt\n",
        "from_data_dir, to_data_dir = to_data_dir, from_data_dir\n",
        "\n",
        "# Tôi từng ước mơ trở thành cầu thủ bóng đá\n",
        "!python $src/back_translate.py \\\n",
        "--decode_hparams=$decode_hparams \\\n",
        "--model=$model_name \\\n",
        "--hparams_set=$hparams_set \\\n",
        "--from_problem=$from_problem \\\n",
        "--to_problem=$to_problem \\\n",
        "--from_ckpt=$from_ckpt \\\n",
        "--to_ckpt=$to_ckpt \\\n",
        "--from_data_dir=$from_data_dir \\\n",
        "--to_data_dir=$to_data_dir \\\n",
        "--backtranslate_interactively\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn5aGaGvADKL"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "This work is made possible by [VietAI](http://vietai.org/).\n",
        "\n",
        "## References\n",
        "\n",
        "1. Improving Neural Machine Translation Models with Monolingual Data - Sennrich et al. , 2016a  ([arxiv](https://arxiv.org/abs/1511.06709))\n",
        "2. Understanding Back-Translation at Scale - Edunov, Sergey, et al., 2018 ([arxiv](https://arxiv.org/abs/1808.09381))\n",
        "3. T2T translate vi<->en tiny tpu - Trieu H. Trinh ([colab](https://colab.research.google.com/drive/1Bx5HfxbmXnMK7kBLHlmGyhVhQVVrDI0p))\n",
        "4. Sentiment Analysis + Back translation - Trieu H. Trinh ([colab](https://colab.research.google.com/drive/1_I0KvFlHFyBcTRT3Bfx9BGLJcIHGJNrG#scrollTo=7yvhttVKTkZu))\n",
        "5. Tensor2Tensor Intro - Tensor2Tensor Team([colab](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb))\n"
      ]
    }
  ]
}