{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vietnamese Backtranslation Model Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vietai/dab/blob/master/colab/Vietnamese_Backtranslation_Model_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuzuxFlWeWh2",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation for Vietnamese Language by Backtranslation\n",
        "\n",
        "Author: Thang Le\n",
        "\n",
        "In this tutorial, we will experiment with using our trained Transformer models to translate interactively from Vietnamese to English and vice versa. We visualize attention weights in the translation models to help you get some idea how Transformer works. Lastly, we make use of these two translation models to do back-translation. Back-translation for languages with limited labeled data such as Vietnamese. The rest of this tutorial is organized as follows:\n",
        "> 1. Mount to [Goolge Cloud Storage](https://cloud.google.com/storage/) for accessing our trained models\n",
        "> 2. Clone some source codes needed\n",
        "> 3. Prepare [tensor2tenor](https://github.com/tensorflow/tensor2tensor) models for inference\n",
        "> 4. Interactive Translation\n",
        "> 5. Attention Visualization\n",
        "> 6. Vietnamese Data Augmentation by Back Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWJLbBMYow0S",
        "colab_type": "text"
      },
      "source": [
        "## I. Mount to Google Cloud Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lAs9IosrZAG",
        "colab_type": "text"
      },
      "source": [
        "We haved managed to train  **Vi --> En** and **En --> Vi** translation models and placed them on Google Cloud Storage. For inference purpose, we need to install **gcsfuse** to access our translation models on Google Cloud Storage\n",
        "\n",
        "NOTE: In case you want to train you own translation models, here is the [colab](https://colab.research.google.com/drive/1Bx5HfxbmXnMK7kBLHlmGyhVhQVVrDI0p#scrollTo=cTUSADz_ti63) to check out! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRO6TXGLT4Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\nInstalling gcsfuse')\n",
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wEzNESRFnxl",
        "colab_type": "text"
      },
      "source": [
        "Let's import some necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuA_J2nnUHWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "from itertools import product\n",
        "\n",
        "import collections\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Enable TF Eager execution\n",
        "tfe = tf.contrib.eager\n",
        "tfe.enable_eager_execution()\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9priC3hHUVaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we mount the local storage to the google cloud bucket.\n",
        "bucket = 'vien-translation'\n",
        "print('Mounting bucket {} to local.'.format(bucket))\n",
        "mount_point = '/content/{}'.format(bucket)\n",
        "\n",
        "if not os.path.exists(mount_point):\n",
        "  tf.gfile.MakeDirs(mount_point)\n",
        "\n",
        "!fusermount -u $mount_point\n",
        "!gcsfuse --implicit-dirs $bucket $mount_point\n",
        "!ls $mount_point"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wbdyg4Erf6g",
        "colab_type": "text"
      },
      "source": [
        "## II. Pull or Clone Some Source Codes\n",
        "\n",
        "To do Vietnamese <--> English translation, we need to make use of Tensor2Tensor problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eHgQvCwqUPp",
        "colab_type": "text"
      },
      "source": [
        "### From our VietAI's github `vietai/dab`\n",
        "\n",
        "We clone from `vietai/dab` for declaring ViEn problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ceNVTXipHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src = '/content/dab'\n",
        "if not os.path.exists(src):\n",
        "    !git clone https://github.com/vietai/dab.git\n",
        "    %cd $src\n",
        "else:\n",
        "    %cd $src\n",
        "    !git pull\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qp_OLevrxlK",
        "colab_type": "text"
      },
      "source": [
        "### From Tensor2Tensor\n",
        "We then build Tensor2Tensor from source and import it for later usage. Because the tensor2tensor library provide EnVi problem only, we need to run **dab/problems.py** to register ViEn problem (for translating from Vietnamese in English) to tensor2tensor registry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgMe553hvYLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"tensor2tensor\"):\n",
        "    !git clone https://github.com/azraelzhor/tensor2tensor.git\n",
        "    %cd tensor2tensor\n",
        "else:\n",
        "    %cd tensor2tensor\n",
        "    !git pull\n",
        "\n",
        "!pip install -q -v .\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.layers import common_layers\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "from tensor2tensor.visualization import attention\n",
        "from tensor2tensor.data_generators import text_encoder, translate_envi\n",
        "%run ../problems.py\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW8CuXXpxZo5",
        "colab_type": "text"
      },
      "source": [
        "## III. Prepare Tensor2Tensor Models for Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zEgVRp5sJZd",
        "colab_type": "text"
      },
      "source": [
        "### General configuration\n",
        "Here we set up some configuration to make sure that we get access to the right directories which store our trained translation models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tux3qqkcZA7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "envi_dir = os.path.join(mount_point, \"checkpoints/translate_envi_iwslt32k_tiny/avg\")\n",
        "vien_dir = os.path.join(mount_point, \"checkpoints/translate_vien_iwslt32k_tiny/avg\")\n",
        "\n",
        "envi_data_dir = os.path.join(mount_point, \"data/translate_envi_iwslt32k\")\n",
        "vien_data_dir = os.path.join(mount_point, \"data/translate_vien_iwslt32k\")\n",
        "\n",
        "vien_ckpt_path = os.path.join(vien_dir, \"model.ckpt-50000\")\n",
        "envi_ckpt_path = os.path.join(envi_dir, \"model.ckpt-50000\")\n",
        "\n",
        "Modes = tf.estimator.ModeKeys\n",
        "\n",
        "# Create hparams and the model\n",
        "model_name = \"transformer\"\n",
        "hparams_set = \"transformer_tiny\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySHTIwkiwH_Q",
        "colab_type": "text"
      },
      "source": [
        "### Vi_En Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S6AwB_4m3Zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vien_problem = problems.problem(\"translate_vien_iwslt32k\")\n",
        "\n",
        "# Get the encoders from the problem\n",
        "vien_encoders = vien_problem.feature_encoders(vien_data_dir)\n",
        "\n",
        "\n",
        "# Setup helper functions for encoding and decoding\n",
        "def vien_encode(input_str, output_str=None):\n",
        "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  inputs = vien_encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
        "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
        "  return {\"inputs\": batch_inputs, \"target_space_id\": tf.constant(1, dtype=tf.int32)}\n",
        "\n",
        "def vien_decode(integers):\n",
        "  \"\"\"List of ints to str\"\"\"\n",
        "  integers = list(np.squeeze(integers))\n",
        "  if 1 in integers:\n",
        "    integers = integers[:integers.index(1)]\n",
        "  return vien_encoders[\"inputs\"].decode(np.squeeze(integers))\n",
        "\n",
        "\n",
        "hparams = trainer_lib.create_hparams(hparams_set, data_dir=vien_data_dir, problem_name=\"translate_vien_iwslt32k\")\n",
        "\n",
        "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
        "# Layer and so subsequent instantiations will have different variable scopes\n",
        "# that will not match the checkpoint.\n",
        "translate_vien_model = registry.model(model_name)(hparams, Modes.EVAL)\n",
        "\n",
        "\n",
        "# Restore and translate!\n",
        "def translate_vien(inputs, beam_size=4, alpha=0.6):\n",
        "  encoded_inputs = vien_encode(inputs)\n",
        "\n",
        "  with tfe.restore_variables_on_create(vien_ckpt_path):\n",
        "    translated_outputs = translate_vien_model.infer(encoded_inputs, beam_size=beam_size, alpha=alpha)\n",
        "        \n",
        "  return vien_decode(translated_outputs[\"outputs\"]), translated_outputs[\"cache\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZgQUyCtwXWE",
        "colab_type": "text"
      },
      "source": [
        "### En_Vi Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-LcLhGvu4_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "envi_problem = problems.problem(\"translate_envi_iwslt32k\")\n",
        "\n",
        "# Get the encoders from the problem\n",
        "envi_encoders = envi_problem.feature_encoders(envi_data_dir)\n",
        "\n",
        "envi_hparams = trainer_lib.create_hparams(hparams_set, data_dir=envi_data_dir, problem_name=\"translate_envi_iwslt32k\")\n",
        "translate_envi_model = registry.model(model_name)(envi_hparams, Modes.EVAL)\n",
        "\n",
        "\n",
        "# Setup helper functions for encoding and decoding\n",
        "def envi_encode(input_str, output_str=None):\n",
        "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  inputs = envi_encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
        "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
        "  return {\"inputs\": batch_inputs, \"target_space_id\": tf.constant(1, dtype=tf.int32)}\n",
        "\n",
        "def envi_decode(integers):\n",
        "  \"\"\"List of ints to str\"\"\"\n",
        "  integers = list(np.squeeze(integers))\n",
        "  if 1 in integers:\n",
        "    integers = integers[:integers.index(1)]\n",
        "  return envi_encoders[\"inputs\"].decode(np.squeeze(integers))\n",
        "\n",
        "\n",
        "\n",
        "def translate_envi(inputs, beam_size=4, alpha=0.6):\n",
        "    encoded_inputs = envi_encode(inputs)\n",
        "    \n",
        "    with tfe.restore_variables_on_create(envi_ckpt_path):\n",
        "        translated_outputs = translate_envi_model.infer(encoded_inputs, beam_size=beam_size, alpha=alpha)\n",
        "        \n",
        "    return envi_decode(translated_outputs[\"outputs\"]), translated_outputs[\"cache\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gPt4u2Ik9Pl",
        "colab_type": "text"
      },
      "source": [
        "## IV. Interactive Translation\n",
        "In this section, you can test the quality of our trained translation models by input any sentence in Vietnamese or English. The models will then translate the input sentence in one language and print out the output sentence in the other language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SpBpGjzxRpr",
        "colab_type": "text"
      },
      "source": [
        "### From Vietnamese to English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLREuKhVjrxv",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "beam_size = 4 #@param {type: \"integer\"}\n",
        "alpha = 0.6 #@param {type: \"number\"}\n",
        "# Tôi là một giáo viên giỏi\n",
        "vi_input_sentence = \"Tôi là một giáo viên giỏi\" #@param {type:\"raw\"}\n",
        "en_output_sentence, _ = translate_vien(vi_input_sentence, beam_size=beam_size, alpha=alpha)\n",
        "en_output_sentence = en_output_sentence.replace('&apos;', '\\'')\n",
        "print(\"The input sentence is tranlated as: \\n{}\".format(en_output_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIUoUPOSxU8o",
        "colab_type": "text"
      },
      "source": [
        "### From English to Vietnamese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsD9QJjpwxjn",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "beam_size = 4 #@param {type: \"integer\"}\n",
        "alpha = 0.6 #@param {type: \"number\"}\n",
        "\n",
        "# I am a good teacher\n",
        "en_input_sentence = \"I am a good teacher\" #@param {type:\"raw\"}\n",
        "vi_output_sentence, _ = translate_envi(en_input_sentence, beam_size=beam_size, alpha=alpha)\n",
        "print(\"The input sentence is tranlated as: \\n{}\".format(vi_output_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FSxCRh6q7jG",
        "colab_type": "text"
      },
      "source": [
        "## V. Attention Visualization\n",
        "In this section, we will visualize Transformer's attention weights to help you get some insights about how Transformer encode and decode sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgE2fvVjrAj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = \"Tôi là một thầy giáo giỏi\"\n",
        "outputs, cache = translate_vien(inputs, beam_size=1, alpha=0)\n",
        "\n",
        "print(\"Inputs: %s\" % inputs)\n",
        "print(\"Outputs: %s\" % outputs.replace('&apos;', '\\''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnYbRTLYgcxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SIZE = 35\n",
        "\n",
        "def encode_eval(input_str, output_str, encoders):\n",
        "  inputs = tf.reshape(encoders[\"inputs\"].encode(input_str) + [1], [1, -1, 1, 1])  # Make it 3D.\n",
        "  outputs = tf.reshape(encoders[\"inputs\"].encode(output_str) + [1], [1, -1, 1, 1])  # Make it 3D.\n",
        "  return {\"inputs\": inputs, \"targets\": outputs}\n",
        "\n",
        "def get_att_mats(translate_model, hparams):\n",
        "  enc_atts = []\n",
        "  dec_atts = []\n",
        "  encdec_atts = []\n",
        "\n",
        "  for i in range(hparams.num_hidden_layers):\n",
        "    enc_att = translate_model.attention_weights[\n",
        "      \"transformer/body/encoder/layer_%i/self_attention/multihead_attention/dot_product_attention\" % i][0]\n",
        "    dec_att = translate_model.attention_weights[\n",
        "      \"transformer/body/decoder/layer_%i/self_attention/multihead_attention/dot_product_attention\" % i][0]\n",
        "    encdec_att = translate_model.attention_weights[\n",
        "      \"transformer/body/decoder/layer_%i/encdec_attention/multihead_attention/dot_product_attention\" % i][0]\n",
        "    \n",
        "    enc_atts.append(resize(enc_att))\n",
        "    dec_atts.append(resize(dec_att))\n",
        "    encdec_atts.append(resize(encdec_att))\n",
        "\n",
        "  return enc_atts, dec_atts, encdec_atts\n",
        "\n",
        "def resize(np_mat):\n",
        "  # Sum across tokens\n",
        "  np_mat = np_mat[:, :SIZE, :SIZE]\n",
        "  row_sums = np.sum(np_mat, axis=-1)\n",
        "  # Normalize\n",
        "  layer_mat = np_mat / row_sums[:, np.newaxis]\n",
        "  lsh = layer_mat.shape\n",
        "  # Add extra dim for viz code to work.\n",
        "  layer_mat = np.reshape(layer_mat, (1, lsh[0], lsh[1], lsh[2]))\n",
        "  return layer_mat\n",
        "\n",
        "def to_tokens(ids, hparams):\n",
        "  ids = np.squeeze(ids)\n",
        "  subtokenizer = hparams.problem_hparams.vocabulary['targets']\n",
        "  tokens = []\n",
        "  for _id in ids:\n",
        "    if _id == 0:\n",
        "      tokens.append('<PAD>')\n",
        "    elif _id == 1:\n",
        "      tokens.append('<EOS>')\n",
        "    elif _id == -1:\n",
        "      tokens.append('<NULL>')\n",
        "    else:\n",
        "        tokens.append(subtokenizer._subtoken_id_to_subtoken_string(_id))\n",
        "  return tokens\n",
        "\n",
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6WYaMTpzG03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get normalized attention weights for each layer\n",
        "enc_atts, dec_atts, encdec_atts = get_att_mats(translate_vien_model, hparams)\n",
        "\n",
        "dec_atts_revised = [np.repeat(dec_att, dec_att.shape[-1], axis=2) for dec_att in dec_atts]\n",
        "\n",
        "attention_history = cache[\"attention_history\"]\n",
        "encdec_atts_revised = [attention_history[\"layer_0\"], attention_history[\"layer_1\"]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu9JDe5zzuh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp_text = to_tokens(vien_encoders[\"inputs\"].encode(inputs), hparams)\n",
        "out_text = to_tokens(vien_encoders[\"inputs\"].encode(outputs), hparams)\n",
        "\n",
        "call_html()\n",
        "\n",
        "attention.show(inp_text, out_text, enc_atts, dec_atts_revised, encdec_atts_revised)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMjVdzoblyjv",
        "colab_type": "text"
      },
      "source": [
        "## VI. Vietnamese Data Augmentation by Backtranslation\n",
        "In this section, we can input any Vietnamese sentence and get its parapharases in an interactive way. By changing the **beam size** and **length penalty ($\\alpha$)** hyperparameters , we can generate multiple paraphrases for each input sentence.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Below is some fun examples that we tried, you can then try it yourself. Have some fun :v\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* Example 1: Bạn tôi học rất giỏi nhưng bạn không thích học\n",
        "    * Bạn biết đấy , bạn biết đấy , bạn biết đấy , nhưng bạn không thích học .\n",
        "    * Bạn rất giỏi ở trường , nhưng bạn không thích học .\n",
        "---\n",
        "* Example 2: Tôi là ai, và đây là đâu\n",
        "    * Tôi là người mà người dân chủ , và đây là nơi nào ?\n",
        "    * Tôi là ai là người manize , và đây là nơi nào ?\n",
        "    * Tôi là người có thể tự nhiên , và đó là nơi mà nó ở đâu , và đó là nơi mà nó ở đâu ?\n",
        "    * Tôi là người mà người có thể tự nhiên , và đó là nơi này ở đâu , và đó là nơi nào ?\n",
        "---\n",
        "* Example 3:  VietAI là một tổ chức phi lợi nhuận với mục tiêu thúc đẩy sự phát triển của công nghệ AI tại Việt Nam\n",
        "    * VietAI là một tổ chức phi lợi nhuận với sự phát triển của AI ở Việt Nam .\n",
        "---\n",
        "\n",
        "NOTE: We experimented to investigate the effectiveness of Vietnamese augmented data by backtranslation on a sentiment analysis task for Foody comments and it seems promising :3. For more information, please check the [colab](https://colab.research.google.com/drive/1_I0KvFlHFyBcTRT3Bfx9BGLJcIHGJNrG#scrollTo=7yvhttVKTkZu) here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEoMmnXO2UaZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "beam_size = 4 #@param {type: \"integer\"}\n",
        "alpha = 0.6 #@param {type: \"number\"}\n",
        "# Tôi từng ước mơ trở thành cầu thủ bóng đá\n",
        "vi_input_sentence = \"Tôi từng ước mơ trở thành cầu thủ bóng đá\" #@param {type:\"raw\"}\n",
        "print(\"Augmented data:\")\n",
        "\n",
        "en_output_sentence, _ = translate_vien(vi_input_sentence, beam_size=beam_size, alpha=alpha)\n",
        "vi_output_sentence, _ = translate_envi(en_output_sentence, beam_size=beam_size, alpha=alpha)\n",
        "print(vi_output_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn5aGaGvADKL",
        "colab_type": "text"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "This work is made possible by [VietAI](http://vietai.org/). Special thanks to [Thang Luong](http://thangluong.com), [ Trieu H. Trinh](https://thtrieu.github.io/) and Phat Hoang for collaborating and giving comments.\n",
        "\n",
        "## References\n",
        "\n",
        "1. Improving Neural Machine Translation Models with Monolingual Data - Sennrich et al. , 2016a  ([arxiv](https://arxiv.org/abs/1511.06709))\n",
        "2. Understanding Back-Translation at Scale - Edunov, Sergey, et al., 2018 ([arxiv](https://arxiv.org/abs/1808.09381))\n",
        "3. T2T translate vi<->en tiny tpu - Trieu H. Trinh ([colab](https://colab.research.google.com/drive/1Bx5HfxbmXnMK7kBLHlmGyhVhQVVrDI0p))\n",
        "4. Sentiment Analysis + Back translation - Trieu H. Trinh ([colab](https://colab.research.google.com/drive/1_I0KvFlHFyBcTRT3Bfx9BGLJcIHGJNrG#scrollTo=7yvhttVKTkZu))\n",
        "5. Tensor2Tensor Intro - Tensor2Tensor Team([colab](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb))\n"
      ]
    }
  ]
}